---
title: 从零开始爬草榴成人文学 (3) – 聚类和PCA
tags:
  - PCA
  - 草榴
url: 2546.html
id: 2546
categories:
  - Python
date: 2019-07-19 15:58:11
---

本文继续上一章对爬到的数据按照文章标题进行分析。

首先使用结巴分词对爬到的标题进行分词，得到分词过后的带空格的标题

import jieba
import jieba.analyse
import jieba.posseg as pseg #引入词性标注接口 
import codecs,sys
items\['split_title'\] = ''

def split_titles(df):
    strs = ' '.join(jieba.cut(df\['lit\_title'\],cut\_all=False))
    return strs
  
items\['split\_title'\] = items.apply(lambda r: split\_titles(r), axis=1)

接着使用TF-IDF按照标题产生每个标题对应的TFIDF向量（因为字典并不大，可以用来作为该标题的嵌入，参考[本博文章](https://l2h.site/2019/07/19/word-embedding-model/)）

import numpy as np
from sklearn.cluster import KMeans
from sklearn import metrics
from sklearn import feature_extraction  
from sklearn.feature_extraction.text import TfidfTransformer  
from sklearn.feature_extraction.text import CountVectorizer  

corpus = items\['split_title'\].tolist()#将文章标题视作TF-IDF的语料
vectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a\[i\]\[j\] 表示j词在i类文本下的词频  
transformer=TfidfTransformer()#该类会统计每个词语的tf-idf权值  
tfidf=transformer.fit\_transform(vectorizer.fit\_transform(corpus))#第一个fit\_transform是计算tf-idf，第二个fit\_transform是将文本转为词频矩阵  
weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a\[i\]\[j\]表示j词在i类文本中的tf-idf权重  

对TFIDF嵌入处理后的向量进行PCA降维（降至2维，方便绘图）

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

new_df = pd.DataFrame(weight)
cls=KMeans(n\_clusters=2).fit(new\_df)

pca = PCA(n_components=2)
new\_pca = pd.DataFrame(pca.fit\_transform(new_df), columns={'A','B'})

plt.scatter(new\_pca\['A'\], new\_pca\['B'\])
plt.show()

![](https://l2h.site/wp-content/uploads/2019/07/屏幕快照-2019-07-19-下午3.49.09.png)

按标题聚类并PCA降维后的文章分布

上图可以看出，有两类文章偏离较远，我们可以看看是什么文章：

for i in list(new\_pca\[new\_pca\['B'\]>0.6\].index):
    new\_items = items.reset\_index()
    print(new\_items\['lit\_title'\]\[i\])

打印这些一类文章的标题后我们发现，这是两篇文章被按照章节写成多篇了。

除此之外，还可以做什么？

*   我们的语料库是文章标题本身，内容有限，分类其实是按照标题自身进行分类的。若我们的语料库是更大的词典，经过对大语料库进行训练后，人工提供分类“武侠类”、“现代类”等等，能否将相应文章准确分类？
*   能否抓取文章完整内容进行分词和聚类？避免教坏小朋友，留待大家讨论